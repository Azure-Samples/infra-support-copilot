inc_id: INC019
server_id: SRV004
region: Europe West
date: 2025-06-23T20:14:12Z

# What happened?
Analytic dashboards showed gaps for two hourly windows due to late-arriving data.

# What went wrong and why?
An upstream Kafka topic retention was reduced from 24h to 6h in a cost-saving change. A prolonged backfill consumed time beyond retention, and late partitions were lost.

# How did we respond?
* 20:17 UTC – Data quality alert fired for missing partitions.
* 20:26 UTC – Restored topic retention to 24h and triggered targeted re-ingest from raw storage.
* 21:03 UTC – Gaps filled; incident closed.

# How are we making incidents like this less likely or less impactful?
* Protect critical topics with minimum retention policies (In progress)
* Add guardrails to block reductions without backfill checks (Planned)

# How can customers make incidents like this less impactful?
* Configure dashboards to display data freshness indicators.
* Build tolerance for late data in alert thresholds.
