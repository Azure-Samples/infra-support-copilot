inc_id: INC024
server_id: SRV009
region: Europe West
date: 2025-08-02T06:40:02Z

# What happened?
Dev ML inference tests intermittently timed out when loading large models.

# What went wrong and why?
Container image was rebuilt without model layer caching; each test run downloaded models from remote storage, saturating network bandwidth.

# How did we respond?
* 06:42 UTC – CI timeouts observed; developers engaged.
* 06:51 UTC – Restored layered images with local model cache; added warmup.
* 07:03 UTC – Tests green.

# How are we making incidents like this less likely or less impactful?
* Enforce multi-stage builds with cached model layers (Completed)
* Add pre-warm job for models in CI (In progress)

# How can customers make incidents like this less impactful?
* Use smaller test models for quick validation.
