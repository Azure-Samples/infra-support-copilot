inc_id: INC011
server_id: SRV006
region: Europe West
date: 2025-05-19T10:16:22Z

# What happened?
User-facing APIs depending on Redis experienced increased latency (p95 2.9s) and occasional cache miss storms between 10:16 and 10:44 UTC.

# What went wrong and why?
Hot keys with large values triggered frequent evictions under volatile-lru due to a mis-sized maxmemory setting after recent data growth. Evictions cascaded into thundering herds rebuilding the same keys.

# How did we respond?
* 10:18 UTC – Latency alert fired; on-call engaged.
* 10:24 UTC – Identified top 10 hot keys and eviction spikes in Redis metrics.
* 10:31 UTC – Increased maxmemory by 25% and enabled admission control for large values.
* 10:39 UTC – Implemented per-key jittered recompute backoff.
* 10:44 UTC – Metrics normalized; incident resolved.

# How are we making incidents like this less likely or less impactful?
* Add autoscaling policy tied to working set estimation (In progress)
* Introduce negative caching and stampede protection (Completed)
* Segment hot keys into dedicated shard (Planned)

# How can customers make incidents like this less impactful?
* Implement client-side caching and tolerate brief stale reads for non-critical data.
* Use rate limiting to avoid bursty recomputation on cache misses.
